{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5a4d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32ae4910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0fabccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "        class Net(nn.Module):\n",
    "                def __init__(self):\n",
    "                        super().__init__()\n",
    "                        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "                        self.conv1_bn = nn.BatchNorm2d(6)\n",
    "                        self.pool = nn.MaxPool2d(2, 2)\n",
    "                        self.conv2 = nn.Conv2d(6, 8, 9)\n",
    "                        self.conv2_bn = nn.BatchNorm2d(8)\n",
    "                        self.fc1 = nn.Linear(8 * 3 * 3, 30)\n",
    "                        self.fc1_bn = nn.BatchNorm1d(30)\n",
    "                        self.fc2 = nn.Linear(30, 20)\n",
    "                        self.fc2_bn = nn.BatchNorm1d(20)\n",
    "                        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "                def forward(self, x):\n",
    "                        x = self.pool(F.elu( self.conv1_bn(self.conv1(x))  ))\n",
    "                        x = self.pool(F.elu( self.conv2_bn(self.conv2(x))  ))\n",
    "                        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "                        x = F.elu( self.fc1_bn(self.fc1(x)) )\n",
    "                        x = F.elu( self.fc2_bn(self.fc2(x)) )\n",
    "                        x = self.fc3(x)\n",
    "                        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaef0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model = Net().to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5237f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.366 acc: 0.089  norm of grandient =  1.4859647110109397\n",
      "[11,     1] loss: 2.286 acc: 0.135  norm of grandient =  1.2788155500293428\n",
      "[21,     1] loss: 2.181 acc: 0.198  norm of grandient =  1.1155429978194322\n",
      "[31,     1] loss: 2.099 acc: 0.240  norm of grandient =  0.8319969686678818\n",
      "[41,     1] loss: 2.043 acc: 0.272  norm of grandient =  0.7525410738803914\n",
      "[51,     1] loss: 1.996 acc: 0.313  norm of grandient =  0.6584445130151481\n",
      "[61,     1] loss: 1.955 acc: 0.338  norm of grandient =  0.6179793983114326\n",
      "[71,     1] loss: 1.919 acc: 0.371  norm of grandient =  0.5890151475850511\n",
      "[81,     1] loss: 1.885 acc: 0.385  norm of grandient =  0.5715705582525021\n",
      "[91,     1] loss: 1.854 acc: 0.407  norm of grandient =  0.557795034623814\n",
      "Finished Training\n",
      "total time = 1.0070459842681885 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    if i >= 1:\n",
    "        break\n",
    "\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    \n",
    "inputs = inputs.to(device=device)\n",
    "labels = labels.to(device=device)\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss = loss.item()\n",
    "\n",
    "    acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('[%d, %5d] loss: %.3f acc: %.3f' % (epoch + 1, 0 + 1, running_loss, acc ), end = \"\")\n",
    "        \n",
    "        total_norm = 0\n",
    "        for p in model.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "        total_norm = total_norm ** (1. / 2)\n",
    "        print( \"  norm of grandient = \", total_norm )\n",
    "        \n",
    "#     print(\"\\n\\n\\n\\n\\nPrint Gradient\\n\\n\\n\\n\\n\")\n",
    "#     lst = list(model.parameters())\n",
    "\n",
    "#     for i in range(len(lst)):\n",
    "# #         print(lst[i].grad.shape)\n",
    "#         print( \"norm of grandient = \", torch.norm(lst[i].grad) )\n",
    "\n",
    "print('Finished Training')\n",
    "end = time.time()\n",
    "print(\"total time = {} s\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82074dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0]\n",
    "# labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838cfc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvar = 10160\n",
    "# x = .1 * np.ones((nvar,1))\n",
    "# x_torch = torch.from_numpy(x).cuda()\n",
    "# torch.nn.utils.vector_to_parameters(x_torch, model.parameters())\n",
    "\n",
    "lst = list(model.parameters())\n",
    "\n",
    "for i in range(len(lst)):\n",
    "    print(lst[i].grad.shape)\n",
    "    print(lst[i].grad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5caa17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc0 = nn.Linear(3*4*4, 20)\n",
    "        self.fc01 = nn.Linear(20, 10)\n",
    "#         self.fc1 = nn.Linear(3 * 16 * 16, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc0(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        x = self.fc01(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#                 def __init__(self):\n",
    "#                         super().__init__()\n",
    "#                         self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "#                         self.fc1 = nn.Linear(3 * 8 * 8, 120)\n",
    "#                         self.fc2 = nn.Linear(120, 84)\n",
    "#                         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#                 def forward(self, x):\n",
    "#                         x = self.pool(x)\n",
    "#                         x = self.pool(x)\n",
    "#                         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#                         x = self.fc1(x)\n",
    "#                         x = self.fc2(x)\n",
    "#                         x = self.fc3(x)\n",
    "#                         return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvar = 10160\n",
    "x = .1 * np.ones((nvar,1))\n",
    "x_torch = torch.from_numpy(x).cuda()\n",
    "torch.nn.utils.vector_to_parameters(x_torch, model.parameters())\n",
    "\n",
    "lst = list(model.parameters())\n",
    "\n",
    "for i in range(len(lst)):\n",
    "#     print(lst[i].grad.shape)\n",
    "    if i == 0:\n",
    "        print(lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395253a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 196 == 195:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 196))\n",
    "            running_loss = 0.0\n",
    "            acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "            print('[%d, %5d] loss: %.3f acc: %.3f' % (epoch + 1, i + 1, running_loss, acc ))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#         if i >= 1:\n",
    "#             break\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss = loss.item()\n",
    "        \n",
    "        acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "        \n",
    "        \n",
    "        print('[%d, %5d] loss: %.3f acc: %.3f' % (epoch + 1, i + 1, running_loss, acc ))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01200b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c06257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58777a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc0 = nn.Linear(3*4*4, 20)\n",
    "        self.fc01 = nn.Linear(20, 10)\n",
    "#         self.fc1 = nn.Linear(3 * 16 * 16, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc0(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        x = self.fc01(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#                 def __init__(self):\n",
    "#                         super().__init__()\n",
    "#                         self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "#                         self.fc1 = nn.Linear(3 * 8 * 8, 120)\n",
    "#                         self.fc2 = nn.Linear(120, 84)\n",
    "#                         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#                 def forward(self, x):\n",
    "#                         x = self.pool(x)\n",
    "#                         x = self.pool(x)\n",
    "#                         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#                         x = self.fc1(x)\n",
    "#                         x = self.fc2(x)\n",
    "#                         x = self.fc3(x)\n",
    "#                         return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        if i >= 1:\n",
    "            break\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss = loss.item()\n",
    "        \n",
    "        acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "        \n",
    "        \n",
    "        print('[%d, %5d] loss: %.3f acc: %.3f' % (epoch + 1, i + 1, running_loss, acc ))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cdf1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([6])\n",
      "torch.Size([6])\n",
      "torch.Size([8, 6, 9, 9])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([30, 72])\n",
      "torch.Size([30])\n",
      "torch.Size([30])\n",
      "torch.Size([30])\n",
      "torch.Size([20, 30])\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "parameter_lst = list(model.parameters())\n",
    "\n",
    "for i in range(len(parameter_lst)):\n",
    "    print(parameter_lst[i].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3aa7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc28f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f253c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84185a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914851fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    acc = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        if i >= 1:\n",
    "            break\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        print(inputs.shape)\n",
    "        print(inputs[0][0])\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "#         print(outputs.shape)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # print statistics\n",
    "        running_loss = loss.item()\n",
    "        \n",
    "        acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "        \n",
    "        \n",
    "        print('[%d, %5d] loss: %.3f acc: %.3f' % (epoch + 1, i + 1, running_loss, acc ))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142373ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(model.parameters())\n",
    "for i in range(len(lst)):\n",
    "#     print(lst[i].shape)\n",
    "    print(lst[i].grad.shape)\n",
    "    if i == 0:\n",
    "        print(lst[0].grad[0])\n",
    "\n",
    "inputs, labels = data\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "\n",
    "lst = list(model.parameters())\n",
    "for i in range(len(lst)):\n",
    "#     print(lst[i].shape)\n",
    "    print(lst[i].grad.shape)\n",
    "    if i == 0:\n",
    "        print(lst[0].grad[0])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf298bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lst[0].grad.shape)\n",
    "vec = torch.reshape(lst[0].grad,(-1,1)).numpy()\n",
    "print(vec.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95743fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
