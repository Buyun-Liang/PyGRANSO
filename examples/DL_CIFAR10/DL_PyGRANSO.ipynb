{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5a4d368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21cd5336ed0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "torch.manual_seed(0)\n",
    "\n",
    "trainset = trainset.to(device=device, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32ae4910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0fabccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "        class Net(nn.Module):\n",
    "                def __init__(self):\n",
    "                        super().__init__()\n",
    "                        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "                        self.conv1_bn = nn.BatchNorm2d(6)\n",
    "                        self.pool = nn.MaxPool2d(2, 2)\n",
    "                        self.conv2 = nn.Conv2d(6, 8, 9)\n",
    "                        self.conv2_bn = nn.BatchNorm2d(8)\n",
    "                        self.fc1 = nn.Linear(8 * 3 * 3, 30)\n",
    "                        self.fc1_bn = nn.BatchNorm1d(30)\n",
    "                        self.fc2 = nn.Linear(30, 20)\n",
    "                        self.fc2_bn = nn.BatchNorm1d(20)\n",
    "                        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "                def forward(self, x):\n",
    "                        x = self.pool(F.elu( self.conv1_bn(self.conv1(x))  ))\n",
    "                        x = self.pool(F.elu( self.conv2_bn(self.conv2(x))  ))\n",
    "                        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "                        x = F.elu( self.fc1_bn(self.fc1(x)) )\n",
    "                        x = F.elu( self.fc2_bn(self.fc2(x)) )\n",
    "                        x = self.fc3(x)\n",
    "                        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaef0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5237f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Buyun\\anaconda3\\envs\\profiling_DL_pygranso_env\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 2.395 acc: 0.102  norm of grandient =  1.4739505626526026\n",
      "[11,     1] loss: 2.313 acc: 0.140  norm of grandient =  1.2999841136117043\n",
      "[21,     1] loss: 2.211 acc: 0.182  norm of grandient =  0.9388309518502852\n",
      "[31,     1] loss: 2.144 acc: 0.230  norm of grandient =  0.7679406073610656\n",
      "[41,     1] loss: 2.093 acc: 0.254  norm of grandient =  0.6863222340002361\n",
      "[51,     1] loss: 2.050 acc: 0.278  norm of grandient =  0.6494327724560763\n",
      "[61,     1] loss: 2.011 acc: 0.309  norm of grandient =  0.6151031316248401\n",
      "[71,     1] loss: 1.975 acc: 0.329  norm of grandient =  0.5811320765850078\n",
      "[81,     1] loss: 1.943 acc: 0.348  norm of grandient =  0.5520620886651045\n",
      "[91,     1] loss: 1.913 acc: 0.362  norm of grandient =  0.5331753432728125\n",
      "Finished Training\n",
      "total time = 9.692829847335815 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    if i >= 1:\n",
    "        break\n",
    "\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "start = time.time()\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss = loss.item()\n",
    "\n",
    "    acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('[%d, %5d] loss: %.3f acc: %.3f' % (epoch + 1, 0 + 1, running_loss, acc ), end = \"\")\n",
    "        \n",
    "        total_norm = 0\n",
    "        for p in model.parameters():\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "        total_norm = total_norm ** (1. / 2)\n",
    "        print( \"  norm of grandient = \", total_norm )\n",
    "        \n",
    "#     print(\"\\n\\n\\n\\n\\nPrint Gradient\\n\\n\\n\\n\\n\")\n",
    "#     lst = list(model.parameters())\n",
    "\n",
    "#     for i in range(len(lst)):\n",
    "# #         print(lst[i].grad.shape)\n",
    "#         print( \"norm of grandient = \", torch.norm(lst[i].grad) )\n",
    "\n",
    "print('Finished Training')\n",
    "end = time.time()\n",
    "print(\"total time = {} s\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82074dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0]\n",
    "# labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838cfc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvar = 10160\n",
    "# x = .1 * np.ones((nvar,1))\n",
    "# x_torch = torch.from_numpy(x).cuda()\n",
    "# torch.nn.utils.vector_to_parameters(x_torch, model.parameters())\n",
    "\n",
    "lst = list(model.parameters())\n",
    "\n",
    "for i in range(len(lst)):\n",
    "    print(lst[i].grad.shape)\n",
    "    print(lst[i].grad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5caa17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc0 = nn.Linear(3*4*4, 20)\n",
    "        self.fc01 = nn.Linear(20, 10)\n",
    "#         self.fc1 = nn.Linear(3 * 16 * 16, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc0(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        x = self.fc01(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#                 def __init__(self):\n",
    "#                         super().__init__()\n",
    "#                         self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "#                         self.fc1 = nn.Linear(3 * 8 * 8, 120)\n",
    "#                         self.fc2 = nn.Linear(120, 84)\n",
    "#                         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#                 def forward(self, x):\n",
    "#                         x = self.pool(x)\n",
    "#                         x = self.pool(x)\n",
    "#                         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#                         x = self.fc1(x)\n",
    "#                         x = self.fc2(x)\n",
    "#                         x = self.fc3(x)\n",
    "#                         return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca10a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvar = 10160\n",
    "x = .1 * np.ones((nvar,1))\n",
    "x_torch = torch.from_numpy(x).cuda()\n",
    "torch.nn.utils.vector_to_parameters(x_torch, model.parameters())\n",
    "\n",
    "lst = list(model.parameters())\n",
    "\n",
    "for i in range(len(lst)):\n",
    "#     print(lst[i].grad.shape)\n",
    "    if i == 0:\n",
    "        print(lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395253a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0067b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 196 == 195:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 196))\n",
    "            running_loss = 0.0\n",
    "            acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "            print('[%d, %5d] loss: %.3f acc: %.3f' % (epoch + 1, i + 1, running_loss, acc ))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#         if i >= 1:\n",
    "#             break\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss = loss.item()\n",
    "        \n",
    "        acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "        \n",
    "        \n",
    "        print('[%d, %5d] loss: %.3f acc: %.3f' % (epoch + 1, i + 1, running_loss, acc ))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01200b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c06257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58777a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc0 = nn.Linear(3*4*4, 20)\n",
    "        self.fc01 = nn.Linear(20, 10)\n",
    "#         self.fc1 = nn.Linear(3 * 16 * 16, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc0(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        x = self.fc01(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#                 def __init__(self):\n",
    "#                         super().__init__()\n",
    "#                         self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "#                         self.fc1 = nn.Linear(3 * 8 * 8, 120)\n",
    "#                         self.fc2 = nn.Linear(120, 84)\n",
    "#                         self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#                 def forward(self, x):\n",
    "#                         x = self.pool(x)\n",
    "#                         x = self.pool(x)\n",
    "#                         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#                         x = self.fc1(x)\n",
    "#                         x = self.fc2(x)\n",
    "#                         x = self.fc3(x)\n",
    "#                         return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768e7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        if i >= 1:\n",
    "            break\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss = loss.item()\n",
    "        \n",
    "        acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "        \n",
    "        \n",
    "        print('[%d, %5d] loss: %.3f acc: %.3f' % (epoch + 1, i + 1, running_loss, acc ))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cdf1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([6])\n",
      "torch.Size([6])\n",
      "torch.Size([8, 6, 9, 9])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([30, 72])\n",
      "torch.Size([30])\n",
      "torch.Size([30])\n",
      "torch.Size([30])\n",
      "torch.Size([20, 30])\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "parameter_lst = list(model.parameters())\n",
    "\n",
    "for i in range(len(parameter_lst)):\n",
    "    print(parameter_lst[i].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3aa7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc28f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f253c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84185a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914851fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    acc = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        if i >= 1:\n",
    "            break\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        print(inputs.shape)\n",
    "        print(inputs[0][0])\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "#         print(outputs.shape)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # print statistics\n",
    "        running_loss = loss.item()\n",
    "        \n",
    "        acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "        \n",
    "        \n",
    "        print('[%d, %5d] loss: %.3f acc: %.3f' % (epoch + 1, i + 1, running_loss, acc ))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142373ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(model.parameters())\n",
    "for i in range(len(lst)):\n",
    "#     print(lst[i].shape)\n",
    "    print(lst[i].grad.shape)\n",
    "    if i == 0:\n",
    "        print(lst[0].grad[0])\n",
    "\n",
    "inputs, labels = data\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()\n",
    "\n",
    "lst = list(model.parameters())\n",
    "for i in range(len(lst)):\n",
    "#     print(lst[i].shape)\n",
    "    print(lst[i].grad.shape)\n",
    "    if i == 0:\n",
    "        print(lst[0].grad[0])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf298bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lst[0].grad.shape)\n",
    "vec = torch.reshape(lst[0].grad,(-1,1)).numpy()\n",
    "print(vec.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95743fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
