{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5257bb27",
   "metadata": {},
   "source": [
    "# Getting started with 2-variable nonsmooth Rosenbrock objective function\n",
    "\n",
    "This notebook contains examples of how to solve optimization problem with 2-variable nonsmooth Rosenbrock objective function, which subject to simple bound constraints.\n",
    "\n",
    "For more details, please check the documentation website https://pygranso.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfdd50",
   "metadata": {},
   "source": [
    "## Import all necessary modules and add PyGRANSO src folder to system path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ed32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import sys\n",
    "## Adding PyGRANSO directories. Should be modified by user\n",
    "sys.path.append('/home/buyun/Documents/GitHub/PyGRANSO')\n",
    "from pygranso import pygranso\n",
    "from pygransoStruct import Options, Data, GeneralStruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80716b",
   "metadata": {},
   "source": [
    "## Spceify torch device, optimization variables, and corresponding objective and constrained function.\n",
    "\n",
    "Note: please strictly follow the format of evalObjFunction and combinedFunction, which will be used in the PyGRANSO main algortihm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb360e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# variables and corresponding dimensions.\n",
    "var_in = {\"x1\": [1,1], \"x2\": [1,1]}\n",
    "\n",
    "\n",
    "def evalObjFunction(X_struct):\n",
    "    x1 = X_struct.x1\n",
    "    x2 = X_struct.x2\n",
    "    \n",
    "    # enable autodifferentiation\n",
    "    x1.requires_grad_(True)\n",
    "    x2.requires_grad_(True)\n",
    "    # objective function\n",
    "    f = (8 * abs(x1**2 - x2) + (1 - x1)**2)\n",
    "    return f\n",
    "\n",
    "def combinedFunction(X_struct):\n",
    "    x1 = X_struct.x1\n",
    "    x2 = X_struct.x2\n",
    "    # enable autodifferentiation\n",
    "    x1.requires_grad_(True)\n",
    "    x2.requires_grad_(True)\n",
    "    \n",
    "    # objective function\n",
    "    f = (8 * abs(x1**2 - x2) + (1 - x1)**2)\n",
    "\n",
    "    # inequality constraint, matrix form\n",
    "    ci = GeneralStruct()\n",
    "    ci.c1 = (2**0.5)*x1-1  \n",
    "    ci.c2 = 2*x2-1 \n",
    "\n",
    "    # equality constraint \n",
    "    ce = None\n",
    "\n",
    "    return [f,ci,ce]\n",
    "\n",
    "obj_eval_fn = lambda X_struct : evalObjFunction(X_struct)\n",
    "comb_fn = lambda X_struct : combinedFunction(X_struct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f55ace",
   "metadata": {},
   "source": [
    "## Specify user-defined options for PyGRANSO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a65b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = Options()\n",
    "# option for switching QP solver. We only have osqp as the only qp solver in current version. Default is osqp\n",
    "# opts.QPsolver = 'osqp'\n",
    "\n",
    "# set an intial point\n",
    "opts.x0 = torch.ones((2,1), device=device, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bca18c7",
   "metadata": {},
   "source": [
    "## Run main algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "632976b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    ║ \n",
      "Version 1.1.0                                                                                                    ║ \n",
      "MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   2                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  1.41421356237 ║  0.00000000000 ║ 1.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.579471   ║ \n",
      "   1 ║ 1.000000 │  0.70773811042 ║  0.70773811042 ║ 0.000000 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 10.07366   ║ \n",
      "   2 ║ 1.000000 │  0.25401310554 ║  0.25401310554 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.198885   ║ \n",
      "   3 ║ 1.000000 │  0.21478744238 ║  0.21478744238 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.135710   ║ \n",
      "   4 ║ 1.000000 │  0.21422378595 ║  0.21422378595 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.332997   ║ \n",
      "   5 ║ 1.000000 │  0.15330884270 ║  0.15330884270 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.122526   ║ \n",
      "   6 ║ 1.000000 │  0.14804462353 ║  0.14804462353 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.012623   ║ \n",
      "   7 ║ 1.000000 │  0.10856024489 ║  0.10856024489 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.042111   ║ \n",
      "   8 ║ 1.000000 │  0.10482600240 ║  0.10482593538 ║ 6.70e-08 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.003212   ║ \n",
      "   9 ║ 0.590490 │  0.05930348165 ║  0.09776366663 ║ 0.001575 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.028507   ║ \n",
      "  10 ║ 0.590490 │  0.05288121922 ║  0.08955480909 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.013736   ║ \n",
      "  11 ║ 0.590490 │  0.05256976230 ║  0.08902735406 ║ 0.000000 │   -  ║ S  │     6 │ 0.031250 ║     1 │ 0.005027   ║ \n",
      "  12 ║ 0.590490 │  0.05213546649 ║  0.08829187029 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001898   ║ \n",
      "  13 ║ 0.590490 │  0.05097806280 ║  0.08624466915 ║ 5.14e-05 │   -  ║ S  │     4 │ 1.750000 ║     1 │ 2.18e-05   ║ \n",
      "  14 ║ 0.590490 │  0.05079563998 ║  0.08602286233 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 5.10e-05   ║ \n",
      "  15 ║ 0.590490 │  0.05077733823 ║  0.08599186816 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 3.47e-04   ║ \n",
      "  16 ║ 0.590490 │  0.05071543228 ║  0.08588702943 ║ 2.70e-10 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.05e-05   ║ \n",
      "  17 ║ 0.590490 │  0.05067270160 ║  0.08581466510 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 8.76e-06   ║ \n",
      "  18 ║ 0.590490 │  0.05066273369 ║  0.08579778436 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 4.48e-05   ║ \n",
      "  19 ║ 0.590490 │  0.05066184116 ║  0.08579627286 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 2.46e-06   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "  20 ║ 0.590490 │  0.05065742201 ║  0.08578809116 ║ 2.85e-07 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 4.06e-06   ║ \n",
      "  21 ║ 0.228768 │  0.01962567651 ║  0.08578802937 ║ 1.27e-07 │   -  ║ \u001b[33mSI\u001b[0m │    24 │ 1.19e-07 ║     1 │ 4.30e-07   ║ \n",
      "  22 ║ 0.228768 │  0.01962563551 ║  0.08578840563 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.69e-06   ║ \n",
      "  23 ║ 0.228768 │  0.01962558257 ║  0.08578817425 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 1.76e-07   ║ \n",
      "  24 ║ 0.228768 │  0.01962531715 ║  0.08578701404 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.17e-07   ║ \n",
      "  25 ║ 0.228768 │  0.01962530099 ║  0.08578694338 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 1.12e-07   ║ \n",
      "  26 ║ 0.228768 │  0.01962527238 ║  0.08578681833 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 7.24e-08   ║ \n",
      "  27 ║ 0.228768 │  0.01962526814 ║  0.08578679978 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.03e-07   ║ \n",
      "  28 ║ 0.228768 │  0.01962525407 ║  0.08578673829 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 1.23e-07   ║ \n",
      "  29 ║ 0.228768 │  0.01962521414 ║  0.08578643555 ║ 1.94e-08 │   -  ║ S  │     8 │ 4.250000 ║     1 │ 1.85e-07   ║ \n",
      "  30 ║ 0.228768 │  0.01962521395 ║  0.08578643827 ║ 1.94e-08 │   -  ║ \u001b[33mSI\u001b[0m │    33 │ 2.33e-10 ║     1 │ 2.32e-08   ║ \n",
      "  31 ║ 0.109419 │  0.00938668494 ║  0.08578653377 ║ 9.14e-09 │   -  ║ \u001b[33mSI\u001b[0m │    27 │ 1.49e-08 ║     1 │ 1.23e-08   ║ \n",
      "  32 ║ 0.109419 │  0.00938667939 ║  0.08578656654 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 9.53e-08   ║ \n",
      "  33 ║ 0.109419 │  0.00938666755 ║  0.08578645832 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 6.77e-09   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  0.08578645832 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║  0.08578632948 ║ 5.69e-07 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  0.08578643763 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              33                                                                                      ║ \n",
      "Function evaluations:    155                                                                                     ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "Total Wall Time: 0.42049193382263184s\n",
      "tensor([[0.7071],\n",
      "        [0.5000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "soln = pygranso(combinedFunction = comb_fn, objEvalFunction = obj_eval_fn,var_dim_map = var_in, torch_device = device, user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))\n",
    "print(soln.final.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790abfe3",
   "metadata": {},
   "source": [
    "# Advanced Tutorial 1\n",
    "the following example shows how to set PyGRANSO options and how to restart PyGRASNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69083bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================================================================================\n",
      "PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    | \n",
      "Version 1.1.0                                                                                                    | \n",
      "MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   | \n",
      "==================================================================================================================\n",
      "Problem specifications:                                                                                          | \n",
      " # of variables                     :   2                                                                        | \n",
      " # of inequality constraints        :   2                                                                        | \n",
      " # of equality constraints          :   0                                                                        | \n",
      "==================================================================================================================\n",
      "     | <--- Penalty Function --> |                | Total Violation | <--- Line Search ---> | <- Stationarity -> | \n",
      "Iter |    Mu    |      Value     |    Objective   |   Ineq   |  Eq  | SD | Evals |     t    | Grads |    Value   | \n",
      "=====|===========================|================|=================|=======================|====================|\n",
      "   0 | 100.0000 |  21841.7781746 |  218.250000000 | 10.00000 |   -  | -  |     1 | 0.000000 |     1 | 9732.768   | \n",
      "   1 | 34.86784 |  1509.66611872 |  42.9789783006 | 11.08181 |   -  | S  |    10 | 0.001953 |     1 | 546.6038   | \n",
      "   2 | 34.86784 |  1378.57842221 |  39.2815768212 | 8.914529 |   -  | S  |     3 | 1.500000 |     1 | 4.455384   | \n",
      "   3 | 12.15767 |  285.452828054 |  22.6935200208 | 9.552604 |   -  | S  |     2 | 2.000000 |     1 | 0.297144   | \n",
      "   4 | 12.15767 |  264.999595731 |  21.0732808630 | 8.797697 |   -  | S  |     2 | 2.000000 |     1 | 0.603629   | \n",
      "   5 | 4.239116 |  60.5144787250 |  12.1478493778 | 9.018338 |   -  | S  |     2 | 2.000000 |     1 | 0.111610   | \n",
      "   6 | 4.239116 |  53.5399399407 |  10.5181947367 | 8.952094 |   -  | S  |     2 | 0.500000 |     1 | 0.164082   | \n",
      "   7 | 3.815204 |  48.9917031616 |  10.4947962860 | 8.951912 |   -  | S  |     4 | 0.125000 |     1 | 0.033640   | \n",
      "   8 | 3.815204 |  48.7011303503 |  10.4372013183 | 8.881076 |   -  | S  |     2 | 2.000000 |     1 | 0.018555   | \n",
      "   9 | 3.815204 |  48.2564717826 |  10.3422772655 | 8.798572 |   -  | S  |     2 | 2.000000 |     1 | 0.057946   | \n",
      "  10 | 3.815204 |  39.4225027901 |  9.27057783616 | 4.053355 |   -  | S  |     5 | 16.00000 |     1 | 0.001796   | \n",
      "==================================================================================================================\n",
      "Optimization results:                                                                                            | \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   | \n",
      "==================================================================================================================\n",
      "   F |          |                |  9.27057783616 | 4.053355 |   -  |    |       |          |       |            | \n",
      "  MF |          |                |  9.27057783616 | 4.053355 |   -  |    |       |          |       |            | \n",
      "==================================================================================================================\n",
      "Iterations:              10                                                                                      | \n",
      "Function evaluations:    35                                                                                      | \n",
      "PyGRANSO termination code: 4 --- max iterations reached.                                                         | \n",
      "==================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "opts = Options()\n",
    "# set an infeasible initial point\n",
    "opts.x0 = 5.5*torch.ones((2,1), device=device, dtype=torch.double)\n",
    "\n",
    "# By default PyGRANSO will print using extended ASCII characters to 'draw' table borders and some color prints. \n",
    "# If user wants to create a log txt file of the console output, please set opts.print_ascii = True\n",
    "opts.print_ascii = True\n",
    "\n",
    "# By default, PyGRANSO prints an info message about QP solvers, since\n",
    "# PyGRANSO can be used with any QP solver that has a quadprog-compatible\n",
    "# interface.  Let's disable this message since we've already seen it \n",
    "# hundreds of times and can now recite it from memory.  ;-)\n",
    "opts.quadprog_info_msg  = False\n",
    "\n",
    "# Try a very short run. \n",
    "opts.maxit = 10 # default is 1000\n",
    "\n",
    "# PyGRANSO's penalty parameter is on the *objective* function, thus\n",
    "# higher penalty parameter values favor objective minimization more\n",
    "# highly than attaining feasibility.  Let's set PyGRANSO to start off\n",
    "# with a higher initial value of the penalty parameter.  PyGRANSO will\n",
    "# automatically tune the penalty parameter to promote progress towards \n",
    "# feasibility.  PyGRANSO only adjusts the penalty parameter in a\n",
    "# monotonically decreasing fashion.\n",
    "opts.mu0 = 100  # default is 1\n",
    "\n",
    "# start main algorithm\n",
    "soln = pygranso(combinedFunction = comb_fn, objEvalFunction = obj_eval_fn,var_dim_map = var_in, torch_device = device, user_opts = opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e4901",
   "metadata": {},
   "source": [
    "## Let's restart PyGRANSO from the last iterate of the previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53087da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    ║ \n",
      "Version 1.1.0                                                                                                    ║ \n",
      "MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   2                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 3.815204 │  39.4225027901 ║  9.27057783616 ║ 4.053355 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.161642   ║ \n",
      "   1 ║ 2.503156 │  27.1660390047 ║  9.40556725606 ║ 3.622442 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.052571   ║ \n",
      "   2 ║ 2.252840 │  24.6945188331 ║  9.60502524451 ║ 3.055934 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.123979   ║ \n",
      "   3 ║ 2.027556 │  22.2891608988 ║  9.93655318601 ║ 2.142243 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.327632   ║ \n",
      "   4 ║ 1.642320 │  17.8466452739 ║  10.2830257908 ║ 0.958623 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.398523   ║ \n",
      "   5 ║ 1.642320 │  13.1497433753 ║  8.00680790496 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 1.154732   ║ \n",
      "   6 ║ 1.642320 │  11.5384064911 ║  6.65402782147 ║ 0.610361 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.564675   ║ \n",
      "   7 ║ 1.642320 │  9.64880551497 ║  5.87510570098 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 1.133393   ║ \n",
      "   8 ║ 1.642320 │  3.21350622958 ║  1.95668663238 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.753192   ║ \n",
      "   9 ║ 1.642320 │  3.21226412269 ║  1.95593032018 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.220255   ║ \n",
      "  10 ║ 1.642320 │  2.59795739787 ║  1.58188226465 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.043072   ║ \n",
      "  11 ║ 1.642320 │  2.09176742524 ║  1.27366591710 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.279000   ║ \n",
      "  12 ║ 1.642320 │  1.74520134120 ║  1.06264369544 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.274270   ║ \n",
      "  13 ║ 1.642320 │  1.64299440242 ║  1.00041044100 ║ 0.000000 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 0.197014   ║ \n",
      "  14 ║ 1.642320 │  1.53354343110 ║  0.93376633416 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.016663   ║ \n",
      "  15 ║ 1.642320 │  1.39121409405 ║  0.84710276755 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.150110   ║ \n",
      "  16 ║ 1.642320 │  1.13011272088 ║  0.68811954794 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.020198   ║ \n",
      "  17 ║ 1.642320 │  0.90384968079 ║  0.55034920169 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.266245   ║ \n",
      "  18 ║ 1.642320 │  0.74426108627 ║  0.45317656618 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.281934   ║ \n",
      "  19 ║ 1.642320 │  0.73336225935 ║  0.44654032917 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.153809   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "  20 ║ 1.642320 │  0.65313994178 ║  0.39769339215 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.010051   ║ \n",
      "  21 ║ 1.642320 │  0.51712938228 ║  0.31487729515 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.144251   ║ \n",
      "  22 ║ 1.642320 │  0.51420110161 ║  0.31309428082 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.233419   ║ \n",
      "  23 ║ 1.642320 │  0.44559794297 ║  0.27132218709 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.005483   ║ \n",
      "  24 ║ 1.642320 │  0.41041962295 ║  0.24990229753 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.159475   ║ \n",
      "  25 ║ 1.642320 │  0.40835629341 ║  0.24864594728 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.012643   ║ \n",
      "  26 ║ 1.642320 │  0.37284178441 ║  0.22702135407 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.005476   ║ \n",
      "  27 ║ 1.642320 │  0.30046617619 ║  0.18295223611 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.037208   ║ \n",
      "  28 ║ 1.642320 │  0.25490108333 ║  0.15520789652 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.114634   ║ \n",
      "  29 ║ 1.642320 │  0.23921712793 ║  0.14565802056 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.107608   ║ \n",
      "  30 ║ 1.642320 │  0.19572753423 ║  0.11917744123 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.010949   ║ \n",
      "  31 ║ 1.642320 │  0.19133582536 ║  0.11650335336 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.066367   ║ \n",
      "  32 ║ 1.642320 │  0.17587939771 ║  0.10709201782 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.012300   ║ \n",
      "  33 ║ 1.642320 │  0.16877931757 ║  0.09825795912 ║ 0.003779 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.012619   ║ \n",
      "  34 ║ 1.642320 │  0.14835173837 ║  0.09033057434 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.003664   ║ \n",
      "  35 ║ 1.642320 │  0.14587855914 ║  0.08882466883 ║ 0.000000 │   -  ║ S  │     4 │ 0.375000 ║     1 │ 0.004583   ║ \n",
      "  36 ║ 1.642320 │  0.14276618493 ║  0.08692956094 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 7.64e-04   ║ \n",
      "  37 ║ 1.642320 │  0.14091133812 ║  0.08579957784 ║ 9.47e-07 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 7.57e-05   ║ \n",
      "  38 ║ 1.642320 │  0.14089141931 ║  0.08578802625 ║ 0.000000 │   -  ║ S  │     6 │ 0.031250 ║     1 │ 3.93e-05   ║ \n",
      "  39 ║ 0.572642 │  0.04912562352 ║  0.08578757518 ║ 8.15e-08 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.75e-07   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "  40 ║ 0.572642 │  0.04912504964 ║  0.08578667063 ║ 2.56e-08 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001680   ║ \n",
      "  41 ║ 0.572642 │  0.04912494429 ║  0.08578652003 ║ 6.51e-09 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.001210   ║ \n",
      "  42 ║ 0.572642 │  0.04912492336 ║  0.08578649484 ║ 0.000000 │   -  ║ S  │    14 │ 1.22e-04 ║     1 │ 1.54e-07   ║ \n",
      "  43 ║ 0.572642 │  0.04912492161 ║  0.08578649178 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 6.74e-08   ║ \n",
      "  44 ║ 0.572642 │  0.04912491178 ║  0.08578644380 ║ 1.25e-08 │   -  ║ S  │     6 │ 2.750000 ║     1 │ 6.01e-08   ║ \n",
      "  45 ║ 0.199668 │  0.01712880836 ║  0.08578644866 ║ 9.48e-09 │   -  ║ \u001b[33mSI\u001b[0m │    31 │ 9.31e-10 ║     1 │ 4.00e-09   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  0.08578644866 ║ 9.48e-09 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║  0.08578642761 ║ 1.24e-07 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  0.08578644704 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              45                                                                                      ║ \n",
      "Function evaluations:    137                                                                                     ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "opts = Options()\n",
    "# set the initial point and penalty parameter to their final values from the previous run\n",
    "opts.x0 = soln.final.x\n",
    "opts.mu0 = soln.final.mu\n",
    "\n",
    "# PREPARE TO RESTART PyGRANSO IN FULL-MEMORY MODE\n",
    "# Set the last BFGS inverse Hessian approximation as the initial\n",
    "# Hessian for the next run.  Generally this is a good thing to do, and\n",
    "# often it is necessary to retain this information when restarting (as\n",
    "# on difficult nonsmooth problems, PyGRANSO may not be able to restart\n",
    "# without it).  However, your mileage may vary.  In the test, with\n",
    "# the above settings, omitting H0 causes PyGRANSO to take an additional \n",
    "# 16 iterations to converge on this problem. \n",
    "opts.H0 = soln.H_final     # try running with this commented out\n",
    "\n",
    "# When restarting, soln.H_final may fail PyGRANSO's initial check to\n",
    "# assess whether or not the user-provided H0 is positive definite.  If\n",
    "# it fails this test, the test may be disabled by setting opts.checkH0 \n",
    "# to false.\n",
    "# opts.checkH0 = False       % Not needed for this example \n",
    "\n",
    "# If one desires to restart PyGRANSO as if it had never stopped (e.g.\n",
    "# to continue optimization after it hit its maxit limit), then one must\n",
    "# also disable scaling the initial BFGS inverse Hessian approximation \n",
    "# on the very first iterate. \n",
    "opts.scaleH0 = False\n",
    "\n",
    "# Restart PyGRANSO\n",
    "opts.maxit = 100 # increase maximum allowed iterations\n",
    "\n",
    "# Main algorithm\n",
    "soln = pygranso(combinedFunction = comb_fn, objEvalFunction = obj_eval_fn,var_dim_map = var_in, torch_device = device, user_opts = opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef5310c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7071],\n",
       "        [0.5000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln.final.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d015a6",
   "metadata": {},
   "source": [
    "# Advanced Tutorial 2\n",
    "\n",
    "opts below shows the importance of using an initial point that is neither near\n",
    "nor on a nonsmooth manifold, that is, the functions \n",
    "(objective and constraints) should be smooth at and *about* \n",
    "the initial point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c968a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = Options()\n",
    "# Set a randomly generated starting point.  In theory, with probability \n",
    "# one, a randomly selected point will not be on a nonsmooth manifold.\n",
    "opts.x0 = torch.randn((2,1), device=device, dtype=torch.double)   # randomly generated is okay\n",
    "opts.maxit = 100  # we'll use this value of maxit later\n",
    "\n",
    "# However, (0,0) or (1,1) are on the nonsmooth manifold and if GRANSO\n",
    "# is started at either of them, it will break down on the first\n",
    "# iteration.  This example highlights that it is imperative to start\n",
    "# GRANSO at a point where the functions are smooth.\n",
    "\n",
    "# Uncomment either of the following two lines to try starting GRANSO\n",
    "# from (0,0) or (1,1), where the functions are not differentiable. \n",
    "    \n",
    "# opts.x0 = torch.ones((2,1), device=device, dtype=torch.double)     # uncomment this line to try this point\n",
    "# opts.x0 = torch.zeros((2,1), device=device, dtype=torch.double)    # uncomment this line to try this point\n",
    "\n",
    "# Uncomment the following two lines to try starting GRANSO from a\n",
    "# uniformly perturbed version of (1,1).  pert_level needs to be at\n",
    "# least 1e-3 or so to get consistently reliable optimization quality.\n",
    "\n",
    "# pert_level = 1e-3\n",
    "# opts.x0 = (torch.ones((2,1)) + pert_level * (torch.randn((2,1)) - 0.5)).to(device=device, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf39d83",
   "metadata": {},
   "source": [
    "The opts below shows how to use opts.halt_log_fn to create a history of iterates\n",
    "\n",
    "NOTE: NO NEED TO CHANGE ANYTHING BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42b9acec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    ║ \n",
      "Version 1.1.0                                                                                                    ║ \n",
      "MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   2                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  2.10049983321 ║  2.10049983321 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 8.082797   ║ \n",
      "   1 ║ 1.000000 │  1.70636607052 ║  1.70636607052 ║ 0.000000 │   -  ║ S  │     6 │ 0.031250 ║     1 │ 6.031990   ║ \n",
      "   2 ║ 1.000000 │  0.97234454954 ║  0.97234454954 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.136329   ║ \n",
      "   3 ║ 1.000000 │  0.92766125457 ║  0.92766125457 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.072550   ║ \n",
      "   4 ║ 1.000000 │  0.81635797850 ║  0.81635797850 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.054010   ║ \n",
      "   5 ║ 1.000000 │  0.64864569214 ║  0.64864569214 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.038895   ║ \n",
      "   6 ║ 1.000000 │  0.59358901709 ║  0.59358901709 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.011874   ║ \n",
      "   7 ║ 1.000000 │  0.50822725694 ║  0.50822725694 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.166660   ║ \n",
      "   8 ║ 1.000000 │  0.48167210415 ║  0.48167210415 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.199436   ║ \n",
      "   9 ║ 1.000000 │  0.45000980809 ║  0.45000980809 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.030973   ║ \n",
      "  10 ║ 1.000000 │  0.44496945433 ║  0.44496945433 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.168192   ║ \n",
      "  11 ║ 1.000000 │  0.40519105451 ║  0.40519105451 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.020663   ║ \n",
      "  12 ║ 1.000000 │  0.38733284603 ║  0.38733284603 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.002060   ║ \n",
      "  13 ║ 1.000000 │  0.35104182913 ║  0.35104182913 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.039421   ║ \n",
      "  14 ║ 1.000000 │  0.27338024152 ║  0.27338024152 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.168972   ║ \n",
      "  15 ║ 1.000000 │  0.25246240127 ║  0.25246240127 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.243226   ║ \n",
      "  16 ║ 1.000000 │  0.20896281512 ║  0.20896281512 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.009345   ║ \n",
      "  17 ║ 1.000000 │  0.20510145309 ║  0.20510145309 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.164587   ║ \n",
      "  18 ║ 1.000000 │  0.18931169782 ║  0.18931169782 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.014273   ║ \n",
      "  19 ║ 1.000000 │  0.17370276831 ║  0.17370276831 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.011821   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "  20 ║ 1.000000 │  0.11783447493 ║  0.11783447493 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 0.100888   ║ \n",
      "  21 ║ 1.000000 │  0.10066262015 ║  0.10066262015 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.021939   ║ \n",
      "  22 ║ 1.000000 │  0.09693553514 ║  0.09693553514 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001399   ║ \n",
      "  23 ║ 0.900000 │  0.07741204432 ║  0.08596458807 ║ 4.39e-05 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 7.06e-04   ║ \n",
      "  24 ║ 0.313811 │  0.02696726527 ║  0.08583494608 ║ 1.63e-05 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.025855   ║ \n",
      "  25 ║ 0.313811 │  0.02693417547 ║  0.08581806167 ║ 3.56e-06 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.048435   ║ \n",
      "  26 ║ 0.313811 │  0.02693272277 ║  0.08582477172 ║ 0.000000 │   -  ║ S  │    11 │ 9.77e-04 ║     1 │ 4.78e-05   ║ \n",
      "  27 ║ 0.313811 │  0.02692629124 ║  0.08580427676 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 5.34e-06   ║ \n",
      "  28 ║ 0.313811 │  0.02692557860 ║  0.08580200584 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 4.39e-06   ║ \n",
      "  29 ║ 0.313811 │  0.02692527447 ║  0.08580103670 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 4.05e-06   ║ \n",
      "  30 ║ 0.313811 │  0.02692432422 ║  0.08578628549 ║ 2.42e-06 │   -  ║ S  │     8 │ 6.250000 ║     1 │ 3.89e-06   ║ \n",
      "  31 ║ 0.228768 │  0.01962875638 ║  0.08578641878 ║ 2.42e-06 │   -  ║ \u001b[33mSI\u001b[0m │    26 │ 2.98e-08 ║     1 │ 8.65e-07   ║ \n",
      "  32 ║ 0.109419 │  0.00938917782 ║  0.08579885763 ║ 1.15e-06 │   -  ║ \u001b[33mSI\u001b[0m │    20 │ 1.91e-06 ║     1 │ 5.56e-07   ║ \n",
      "  33 ║ 0.109419 │  0.00938803887 ║  0.08579899110 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 4.74e-06   ║ \n",
      "  34 ║ 0.109419 │  0.00938715727 ║  0.08579093392 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 6.87e-07   ║ \n",
      "  35 ║ 0.109419 │  0.00938710544 ║  0.08579046028 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.00e-06   ║ \n",
      "  36 ║ 0.109419 │  0.00938681943 ║  0.08578784635 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 3.16e-07   ║ \n",
      "  37 ║ 0.109419 │  0.00938677086 ║  0.08578740246 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 3.08e-07   ║ \n",
      "  38 ║ 0.109419 │  0.00938675248 ║  0.08578723453 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 5.24e-08   ║ \n",
      "  39 ║ 0.109419 │  0.00938674805 ║  0.08578719403 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 1.00e-07   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "  40 ║ 0.109419 │  0.00938674549 ║  0.08578717063 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.07e-07   ║ \n",
      "  41 ║ 0.109419 │  0.00938667333 ║  0.08578647541 ║ 3.91e-09 │   -  ║ S  │    11 │ 8.375000 ║     1 │ 2.35e-07   ║ \n",
      "  42 ║ 0.109419 │  0.00938667219 ║  0.08578650068 ║ 0.000000 │   -  ║ \u001b[33mSI\u001b[0m │    28 │ 7.45e-09 ║     1 │ 9.66e-08   ║ \n",
      "  43 ║ 0.109419 │  0.00938667027 ║  0.08578648314 ║ 0.000000 │   -  ║ S  │     5 │ 0.062500 ║     1 │ 6.46e-07   ║ \n",
      "  44 ║ 0.109419 │  0.00938666786 ║  0.08578646117 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.39e-08   ║ \n",
      "  45 ║ 0.109419 │  0.00938666684 ║  0.08578645180 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.31e-08   ║ \n",
      "  46 ║ 0.109419 │  0.00938666671 ║  0.08578645068 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.61e-09   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  0.08578645068 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║  0.08578634052 ║ 6.72e-07 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  0.08578645068 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              46                                                                                      ║ \n",
      "Function evaluations:    182                                                                                     ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "# SETUP THE LOGGING FEATURES\n",
    "    \n",
    "# Set up PyGRANSO's logging functions; pass opts.maxit to it so that\n",
    "# storage can be preallocated for efficiency.\n",
    "\n",
    "class HaltLog:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def haltLog(self, iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized,\n",
    "                ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level):\n",
    "\n",
    "        # DON'T CHANGE THIS\n",
    "        # increment the index/count \n",
    "        self.index += 1                  \n",
    "\n",
    "        # EXAMPLE:\n",
    "        # store history of x iterates in a preallocated cell array\n",
    "        self.x_iterates.append(x)\n",
    "        self.f.append(penaltyfn_parts.f)\n",
    "        self.tv.append(penaltyfn_parts.tv)\n",
    "\n",
    "        # keep this false unless you want to implement a custom termination\n",
    "        # condition\n",
    "        halt = False\n",
    "        return halt\n",
    "    \n",
    "    # Once PyGRANSO has run, you may call this function to get retreive all\n",
    "    # the logging data stored in the shared variables, which is populated \n",
    "    # by haltLog being called on every iteration of PyGRANSO.\n",
    "    def getLog(self):\n",
    "        # EXAMPLE\n",
    "        # return x_iterates, trimmed to correct size \n",
    "        log = GeneralStruct()\n",
    "        log.x   = self.x_iterates[0:self.index]\n",
    "        log.f   = self.f[0:self.index]\n",
    "        log.tv  = self.tv[0:self.index]\n",
    "        return log\n",
    "\n",
    "    def makeHaltLogFunctions(self,maxit):\n",
    "        # don't change these lambda functions \n",
    "        halt_log_fn = lambda iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized, ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level: self.haltLog(iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized, ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level)\n",
    "                \n",
    "        get_log_fn = lambda : self.getLog()\n",
    "\n",
    "        # Make your shared variables here to store PyGRANSO history data\n",
    "        # EXAMPLE - store history of iterates x_0,x_1,...,x_k\n",
    "        self.index       = 0\n",
    "        self.x_iterates  = []\n",
    "        self.f           = []\n",
    "        self.tv          = []\n",
    "\n",
    "        # Only modify the body of logIterate(), not its name or arguments.\n",
    "        # Store whatever data you wish from the current PyGRANSO iteration info,\n",
    "        # given by the input arguments, into shared variables of\n",
    "        # makeHaltLogFunctions, so that this data can be retrieved after PyGRANSO\n",
    "        # has been terminated.\n",
    "        # \n",
    "        # DESCRIPTION OF INPUT ARGUMENTS\n",
    "        #   iter                current iteration number\n",
    "        #   x                   current iterate x \n",
    "        #   penaltyfn_parts     struct containing the following\n",
    "        #       OBJECTIVE AND CONSTRAINTS VALUES\n",
    "        #       .f              objective value at x\n",
    "        #       .f_grad         objective gradient at x\n",
    "        #       .ci             inequality constraint at x\n",
    "        #       .ci_grad        inequality gradient at x\n",
    "        #       .ce             equality constraint at x\n",
    "        #       .ce_grad        equality gradient at x\n",
    "        #       TOTAL VIOLATION VALUES (inf norm, for determining feasibiliy)\n",
    "        #       .tvi            total violation of inequality constraints at x\n",
    "        #       .tve            total violation of equality constraints at x\n",
    "        #       .tv             total violation of all constraints at x\n",
    "        #       TOTAL VIOLATION VALUES (one norm, for L1 penalty function)\n",
    "        #       .tvi_l1         total violation of inequality constraints at x\n",
    "        #       .tvi_l1_grad    its gradient\n",
    "        #       .tve_l1         total violation of equality constraints at x\n",
    "        #       .tve_l1_grad    its gradient\n",
    "        #       .tv_l1          total violation of all constraints at x\n",
    "        #       .tv_l1_grad     its gradient\n",
    "        #       PENALTY FUNCTION VALUES \n",
    "        #       .p              penalty function value at x\n",
    "        #       .p_grad         penalty function gradient at x\n",
    "        #       .mu             current value of the penalty parameter\n",
    "        #       .feasible_to_tol logical indicating whether x is feasible\n",
    "        #   d                   search direction\n",
    "        #   get_BFGS_state_fn   function handle to get the (L)BFGS state data     \n",
    "        #                       FULL MEMORY: \n",
    "        #                       - returns BFGS inverse Hessian approximation \n",
    "        #                       LIMITED MEMORY:\n",
    "        #                       - returns a struct with current L-BFGS state:\n",
    "        #                           .S          matrix of the BFGS s vectors\n",
    "        #                           .Y          matrix of the BFGS y vectors\n",
    "        #                           .rho        row vector of the 1/sty values\n",
    "        #                           .gamma      H0 scaling factor\n",
    "        #   H_regularized       regularized version of H \n",
    "        #                       [] if no regularization was applied to H\n",
    "        #   fn_evals            number of function evaluations incurred during\n",
    "        #                       this iteration\n",
    "        #   alpha               size of accepted size\n",
    "        #   n_gradients         number of previous gradients used for computing\n",
    "        #                       the termination QP\n",
    "        #   stat_vec            stationarity measure vector                 \n",
    "        #   stat_val            approximate value of stationarity:\n",
    "        #                           norm(stat_vec)\n",
    "        #                       gradients (result of termination QP)\n",
    "        #   fallback_level      number of strategy needed for a successful step\n",
    "        #                       to be taken.  See bfgssqpOptionsAdvanced.\n",
    "        #\n",
    "        # OUTPUT ARGUMENT\n",
    "        #   halt                set this to true if you wish optimization to \n",
    "        #                       be halted at the current iterate.  This can be \n",
    "        #                       used to create a custom termination condition,\n",
    "        return [halt_log_fn, get_log_fn]\n",
    "\n",
    "mHLF_obj = HaltLog()\n",
    "[halt_log_fn, get_log_fn] = mHLF_obj.makeHaltLogFunctions(opts.maxit)\n",
    "\n",
    "#  Set PyGRANSO's logging function in opts\n",
    "opts.halt_log_fn = halt_log_fn\n",
    "\n",
    "# Main algorithm with logging enabled.\n",
    "soln = pygranso(combinedFunction = comb_fn, objEvalFunction = obj_eval_fn,var_dim_map = var_in, torch_device = device, user_opts = opts)\n",
    "\n",
    "# GET THE HISTORY OF ITERATES\n",
    "# Even if an error is thrown, the log generated until the error can be\n",
    "# obtained by calling get_log_fn()\n",
    "log = get_log_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "557f5a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.1004998332057183, 1.706366070524201, 0.972344549543489]\n",
      "[tensor([[0.0406],\n",
      "        [0.1491]], dtype=torch.float64), tensor([[ 0.0766],\n",
      "        [-0.1008]], dtype=torch.float64), tensor([[0.0837],\n",
      "        [0.0236]], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "print(log.f[0:3])\n",
    "print(log.x[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc946bc6",
   "metadata": {},
   "source": [
    "# Advanced Tutorial 3\n",
    "\n",
    " PREPARE TO RESTART GRANSO IN LIMITED-MEMORY MODE\n",
    " \n",
    " (Note that this example problem only has two variables!)\n",
    " \n",
    " If PyGRANSO was running in limited-memory mode, that is, if \n",
    " opts.limited_mem_size > 0, then PyGRANSO's restart procedure is \n",
    " slightly different, as soln.H_final will instead contain the most \n",
    " current L-BFGS state, not a full inverse Hessian approximation.  \n",
    " \n",
    " Instead, do the following: \n",
    " 1) If you set a specific H0, you will need to set opts.H0 to whatever\n",
    "    you used previously.  By default, PyGRANSO uses the identity for H0.\n",
    "    \n",
    " 2) Warm-start GRANSO with the most recent L-BFGS data by setting:\n",
    "    opts.limited_mem_warm_start = soln.H_final;\n",
    "    \n",
    " NOTE: how to set opts.scaleH0 so that PyGRANSO will be restarted as if\n",
    " it had never terminated depends on the previously used values of \n",
    " opts.scaleH0 and opts.limited_mem_fixed_scaling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f78321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================================================================================\n",
      "PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    | \n",
      "Version 1.1.0                                                                                                    | \n",
      "MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   | \n",
      "==================================================================================================================\n",
      "Problem specifications:                                                                                          | \n",
      " # of variables                     :   2                                                                        | \n",
      " # of inequality constraints        :   2                                                                        | \n",
      " # of equality constraints          :   0                                                                        | \n",
      "==================================================================================================================\n",
      "Limited-memory mode enabled with size = 1.                                                                       | \n",
      "NOTE: limited-memory mode is generally NOT                                                                       | \n",
      "recommended for nonsmooth problems.                                                                              | \n",
      "==================================================================================================================\n",
      "     | <--- Penalty Function --> |                | Total Violation | <--- Line Search ---> | <- Stationarity -> | \n",
      "Iter |    Mu    |      Value     |    Objective   |   Ineq   |  Eq  | SD | Evals |     t    | Grads |    Value   | \n",
      "=====|===========================|================|=================|=======================|====================|\n",
      "   0 | 100.0000 |  21841.7781746 |  218.250000000 | 10.00000 |   -  | -  |     1 | 0.000000 |     1 | 9732.768   | \n",
      "   1 | 34.86784 |  1509.66611872 |  42.9789783006 | 11.08181 |   -  | S  |    10 | 0.001953 |     1 | 546.6038   | \n",
      "   2 | 34.86784 |  1378.57842221 |  39.2815768212 | 8.914529 |   -  | S  |     3 | 1.500000 |     1 | 4.455384   | \n",
      "   3 | 12.15767 |  284.680804366 |  22.6343943597 | 9.499410 |   -  | S  |     2 | 2.000000 |     1 | 0.300029   | \n",
      "   4 | 12.15767 |  262.610250639 |  20.8774186596 | 8.789579 |   -  | S  |     2 | 2.000000 |     1 | 0.604009   | \n",
      "   5 | 4.239116 |  60.7612760077 |  12.2137750044 | 8.985669 |   -  | S  |     2 | 2.000000 |     1 | 0.109755   | \n",
      "   6 | 4.239116 |  57.9458175917 |  11.5708792009 | 8.895520 |   -  | S  |     3 | 0.750000 |     1 | 0.165224   | \n",
      "   7 | 1.642320 |  26.5358475574 |  10.7424814828 | 8.893252 |   -  | S  |     2 | 2.000000 |     1 | 0.020658   | \n",
      "   8 | 1.642320 |  26.2056730861 |  10.5532019880 | 8.873935 |   -  | S  |     1 | 1.000000 |     1 | 0.027766   | \n",
      "   9 | 1.642320 |  26.1399157398 |  10.5197311583 | 8.863147 |   -  | S  |     1 | 1.000000 |     1 | 0.015427   | \n",
      "  10 | 1.642320 |  25.9163909350 |  10.4174724535 | 8.807564 |   -  | S  |     2 | 2.000000 |     1 | 0.021455   | \n",
      "==================================================================================================================\n",
      "Optimization results:                                                                                            | \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   | \n",
      "==================================================================================================================\n",
      "   F |          |                |  10.4174724535 | 8.807564 |   -  |    |       |          |       |            | \n",
      "  MF |          |                |  75.6886238113 | 8.192103 |   -  |    |       |          |       |            | \n",
      "==================================================================================================================\n",
      "Iterations:              10                                                                                      | \n",
      "Function evaluations:    29                                                                                      | \n",
      "PyGRANSO termination code: 4 --- max iterations reached.                                                         | \n",
      "==================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "opts = Options()\n",
    "# set an infeasible initial point\n",
    "opts.x0 = 5.5*torch.ones((2,1), device=device, dtype=torch.double)\n",
    "\n",
    "opts.print_ascii = True\n",
    "opts.quadprog_info_msg  = False\n",
    "opts.maxit = 10 # default is 1000\n",
    "opts.mu0 = 100  # default is 1\n",
    "\n",
    "# By default, PyGRANSO uses full-memory BFGS updating.  For nonsmooth\n",
    "# problems, full-memory BFGS is generally recommended.  However, if\n",
    "# this is not feasible, one may optionally enable limited-memory BFGS\n",
    "# updating by setting opts.limited_mem_size to a positive integer\n",
    "# (significantly) less than the number of variables.\n",
    "opts.limited_mem_size = 1\n",
    "\n",
    "# start main algorithm\n",
    "soln = pygranso(combinedFunction = comb_fn, objEvalFunction = obj_eval_fn,var_dim_map = var_in, torch_device = device, user_opts = opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e363ffda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any(): argument 'input' (position 1) must be Tensor, not dict\n",
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: Python numerical package using GRadient-based Algorithm for Non-Smooth Optimization                    ║ \n",
      "Version 1.1.0                                                                                                    ║ \n",
      "MIT License Copyright (c) 2021 SUN Group @ UMN                                                                   ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   2                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 1.                                                                      \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                                      \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                                             \u001b[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.642320 │  25.9163909350 ║  10.4174724535 ║ 8.807564 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.154839   ║ \n",
      "   1 ║ 0.572642 │  14.7485315358 ║  10.3734163206 ║ 8.808281 │   -  ║ S  │     5 │ 0.062500 ║     1 │ 0.039662   ║ \n",
      "   2 ║ 0.572642 │  14.7087004862 ║  10.3255844826 ║ 8.795840 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.006717   ║ \n",
      "   3 ║ 0.572642 │  7.55436468764 ║  11.0967484430 ║ 1.199904 │   -  ║ S  │     6 │ 32.00000 ║     1 │ 0.033315   ║ \n",
      "   4 ║ 0.572642 │  7.38735011540 ║  12.9004755474 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.609610   ║ \n",
      "   5 ║ 0.572642 │  6.57954564149 ║  9.53102981194 ║ 1.121681 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.564472   ║ \n",
      "   6 ║ 0.572642 │  5.68850121223 ║  9.93378811659 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.460399   ║ \n",
      "   7 ║ 0.572642 │  4.97609803486 ║  8.16997812076 ║ 0.297628 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.169423   ║ \n",
      "   8 ║ 0.572642 │  4.40481563603 ║  7.69209737126 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.079752   ║ \n",
      "   9 ║ 0.572642 │  2.64647894411 ║  4.62152684951 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 0.167235   ║ \n",
      "  10 ║ 0.572642 │  2.44821944957 ║  4.27530774234 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.149413   ║ \n",
      "  11 ║ 0.572642 │  0.94390250677 ║  1.64833005307 ║ 0.000000 │   -  ║ S  │     6 │ 32.00000 ║     1 │ 0.582259   ║ \n",
      "  12 ║ 0.572642 │  0.84607969867 ║  1.47750279780 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.011596   ║ \n",
      "  13 ║ 0.572642 │  0.72932354206 ║  1.27361237433 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.057381   ║ \n",
      "  14 ║ 0.572642 │  0.53291017622 ║  0.93061714821 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.164963   ║ \n",
      "  15 ║ 0.572642 │  0.39094277341 ║  0.68270050965 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 0.041224   ║ \n",
      "  16 ║ 0.572642 │  0.10905447199 ║  0.19044102787 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.129503   ║ \n",
      "  17 ║ 0.572642 │  0.10226872112 ║  0.17859112070 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.052347   ║ \n",
      "  18 ║ 0.572642 │  0.08331160067 ║  0.14548643972 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.011693   ║ \n",
      "  19 ║ 0.572642 │  0.08298163910 ║  0.14491023024 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.001523   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "  20 ║ 0.572642 │  0.08128162887 ║  0.14194151480 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.002646   ║ \n",
      "  21 ║ 0.572642 │  0.07248770514 ║  0.12658475001 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.016694   ║ \n",
      "  22 ║ 0.572642 │  0.06571586437 ║  0.11475913395 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.039408   ║ \n",
      "  23 ║ 0.572642 │  0.06502831449 ║  0.11355847061 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001552   ║ \n",
      "  24 ║ 0.572642 │  0.06136609522 ║  0.10716316385 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 7.57e-04   ║ \n",
      "  25 ║ 0.572642 │  0.06134545438 ║  0.10712711890 ║ 0.000000 │   -  ║ S  │     7 │ 0.015625 ║     1 │ 0.001192   ║ \n",
      "  26 ║ 0.572642 │  0.05555772556 ║  0.09702005034 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 0.001837   ║ \n",
      "  27 ║ 0.572642 │  0.05454287884 ║  0.09524783093 ║ 0.000000 │   -  ║ S  │     8 │ 0.023438 ║     1 │ 0.017108   ║ \n",
      "  28 ║ 0.572642 │  0.05398282948 ║  0.09426982082 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 8.04e-04   ║ \n",
      "  29 ║ 0.572642 │  0.05281167826 ║  0.09222464799 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.004317   ║ \n",
      "  30 ║ 0.572642 │  0.05005669708 ║  0.08724686093 ║ 9.55e-05 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 4.34e-05   ║ \n",
      "  31 ║ 0.199668 │  0.01735174147 ║  0.08648598851 ║ 8.33e-05 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.043067   ║ \n",
      "  32 ║ 0.199668 │  0.01712917785 ║  0.08578784616 ║ 1.06e-07 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 4.79e-04   ║ \n",
      "  33 ║ 0.199668 │  0.01712892822 ║  0.08578712873 ║ 0.000000 │   -  ║ S  │    10 │ 0.001953 ║     1 │ 1.93e-05   ║ \n",
      "  34 ║ 0.199668 │  0.01712889814 ║  0.08578697811 ║ 0.000000 │   -  ║ S  │    16 │ 3.05e-05 ║     1 │ 1.22e-06   ║ \n",
      "  35 ║ 0.199668 │  0.01712882429 ║  0.08578654893 ║ 1.18e-08 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 1.85e-08   ║ \n",
      "  36 ║ 0.069620 │  0.00597244796 ║  0.08578648609 ║ 4.73e-09 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.007017   ║ \n",
      "  37 ║ 0.069620 │  0.00597244508 ║  0.08578651272 ║ 0.000000 │   -  ║ S  │    14 │ 1.22e-04 ║     1 │ 4.28e-08   ║ \n",
      "  38 ║ 0.069620 │  0.00597244228 ║  0.08578647247 ║ 0.000000 │   -  ║ S  │    18 │ 7.63e-06 ║     1 │ 5.58e-08   ║ \n",
      "  39 ║ 0.069620 │  0.00597244080 ║  0.08578645113 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 3.10e-08   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "  40 ║ 0.069620 │  0.00597244066 ║  0.08578644352 ║ 3.91e-10 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 6.66e-10   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  0.08578644352 ║ 3.91e-10 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║  0.08578644352 ║ 3.91e-10 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  0.08578645113 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              40                                                                                      ║ \n",
      "Function evaluations:    151                                                                                     ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "# Restart\n",
    "opts = Options()\n",
    "# set the initial point and penalty parameter to their final values from the previous run\n",
    "opts.x0 = soln.final.x\n",
    "opts.mu0 = soln.final.mu\n",
    "opts.limited_mem_size = 1\n",
    "\n",
    "opts.H0 = soln.H_final     # try running with this commented out\n",
    "opts.limited_mem_warm_start = soln.H_final\n",
    "opts.scaleH0 = False\n",
    "\n",
    "# In contrast to full-memory BFGS updating, limited-memory BFGS\n",
    "# permits that H0 can be scaled on every iteration.  By default,\n",
    "# PyGRANSO will reuse the scaling parameter that is calculated on the\n",
    "# very first iteration for all subsequent iterations as well.  Set\n",
    "# this option to false to force PyGRANSO to calculate a new scaling\n",
    "# parameter on every iteration.  Note that opts.scaleH0 has no effect\n",
    "# when opts.limited_mem_fixed_scaling is set to true.\n",
    "# opts.limited_mem_fixed_scaling = False\n",
    "\n",
    "# Restart PyGRANSO\n",
    "opts.maxit = 100 # increase maximum allowed iterations\n",
    "\n",
    "# Main algorithm\n",
    "soln = pygranso(combinedFunction = comb_fn, objEvalFunction = obj_eval_fn,var_dim_map = var_in, torch_device = device, user_opts = opts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
