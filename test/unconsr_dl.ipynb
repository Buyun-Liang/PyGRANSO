{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2660de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Initial acc = 0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buyun/anaconda3/envs/cuosqp_pygranso/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import torch\n",
    "import sys\n",
    "## Adding PyGRANSO directories. Should be modified by user\n",
    "sys.path.append('/home/buyun/Documents/GitHub/PyGRANSO')\n",
    "from pygranso import pygranso\n",
    "from pygransoStruct import pygransoStruct \n",
    "from private.getNvar import getNvarTorch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "\n",
    "# ## Data Initialization \n",
    "# Specify torch device, neural network architecture, and generate data.\n",
    "# \n",
    "# NOTE: please specify path for downloading data.\n",
    "# \n",
    "# Use GPU for this problem. If no cuda device available, please set *device = torch.device('cpu')*\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "class Net(nn.Module):\n",
    "     def __init__(self):\n",
    "             super().__init__()\n",
    "             self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "             self.conv1_bn = nn.BatchNorm2d(6)\n",
    "             self.pool = nn.MaxPool2d(2, 2)\n",
    "             self.conv2 = nn.Conv2d(6, 8, 9)\n",
    "             self.conv2_bn = nn.BatchNorm2d(8)\n",
    "             self.fc1 = nn.Linear(8 * 3 * 3, 30)\n",
    "             self.fc1_bn = nn.BatchNorm1d(30)\n",
    "             self.fc2 = nn.Linear(30, 20)\n",
    "             self.fc2_bn = nn.BatchNorm1d(20)\n",
    "             self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "     def forward(self, x):\n",
    "             x = self.pool(F.elu( self.conv1_bn(self.conv1(x))  ))\n",
    "             x = self.pool(F.elu( self.conv2_bn(self.conv2(x))  ))\n",
    "             x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "             x = F.elu( self.fc1_bn(self.fc1(x)) )\n",
    "             x = F.elu( self.fc2_bn(self.fc2(x)) )\n",
    "             x = self.fc3(x)\n",
    "             return x\n",
    "\n",
    "# fix model parameters\n",
    "torch.manual_seed(0)\n",
    "model = Net().to(device=device, dtype=torch.double)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "batch_size = 1000\n",
    "trainset = torchvision.datasets.CIFAR10(root='/home/buyun/Documents/GitHub/PyGRANSO/examples', train=True, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "# data_in\n",
    "for i, data in enumerate(trainloader, 0):        \n",
    "    if i >= 1:\n",
    "         break   \n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    \n",
    "# All the user-provided data (vector/matrix/tensor) must be in torch tensor format. \n",
    "# As PyTorch tensor is single precision by default, one must explicitly set `dtype=torch.double`.\n",
    "# Also, please make sure the device of provided torch tensor is the same as opts.torch_device.\n",
    "labels = labels.to(device=device) # label/target [256]\n",
    "inputs = inputs.to(device=device, dtype=torch.double) # input data [256,3,32,32]\n",
    "\n",
    "\n",
    "# ## Function Set-Up\n",
    "# \n",
    "# Encode the optimization variables, and objective and constraint functions.\n",
    "# \n",
    "# Note: please strictly follow the format of comb_fn, which will be used in the PyGRANSO main algortihm.\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# variables and corresponding dimensions.\n",
    "var_in = {}\n",
    "var_count = 0\n",
    "var_str = \"x\"\n",
    "for i in model.parameters():\n",
    "    # print(i.shape)\n",
    "    var_in[var_str+str(var_count)]= list(i.shape)\n",
    "    var_count += 1\n",
    "    \n",
    "def user_fn(X_struct,model,inputs,labels):\n",
    "    # objective function\n",
    "    var_str = \"x\"\n",
    "    var_count = 0\n",
    "    for p in model.parameters():\n",
    "        tmpstr = var_str+str(var_count)\n",
    "        tmp_parameter = getattr(X_struct,tmpstr)\n",
    "        p.data = tmp_parameter # update model parameters\n",
    "        var_count += 1\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    f = criterion(outputs, labels)\n",
    "    ci = None\n",
    "    ce = None\n",
    "    return [f,ci,ce]\n",
    "\n",
    "comb_fn = lambda X_struct : user_fn(X_struct,model,inputs,labels)\n",
    "\n",
    "\n",
    "# ## User Options\n",
    "# Specify user-defined options for PyGRANSO \n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "opts.maxit = 300\n",
    "opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "opts.opt_tol = 1e-6\n",
    "opts.fvalquit = 1e-6\n",
    "opts.print_level = 1\n",
    "opts.print_frequency = 1\n",
    "# opts.print_ascii = True\n",
    "\n",
    "opts.limited_mem_size = 100\n",
    "\n",
    "\n",
    "# opts.halt_on_linesearch_bracket = False\n",
    "# opts.max_fallback_level = 2\n",
    "# opts.min_fallback_level = 2\n",
    "# # opts.init_step_size = 1e-2\n",
    "# opts.linesearch_maxit = 25\n",
    "# opts.is_backtrack_linesearch = True\n",
    "# opts.search_direction_rescaling = True\n",
    "# opts.disable_terminationcode_6 = True\n",
    "\n",
    "opts.init_step_size = 1\n",
    "\n",
    "\n",
    "# ## Initial Test \n",
    "# Check initial accuracy of the modified LeNet5 model\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "outputs = model(inputs )\n",
    "acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "\n",
    "print(\"Initial acc = {}\".format(acc)) \n",
    "\n",
    "\n",
    "# ## Main Algorithm\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638b06a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m══════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                          ║ \n",
      "Version 1.0.0                                                                                 ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021 Tim Mitchell and Buyun Liang                    ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                       ║ \n",
      " # of variables                     :   7500                                                  ║ \n",
      " # of inequality constraints        :      0                                                  ║ \n",
      " # of equality constraints          :      0                                                  ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001b[33mLimited-memory mode enabled with size = 100.                                                 \u001b[0m ║ \n",
      "\u001b[33mNOTE: limited-memory mode is generally NOT                                                   \u001b[0m ║ \n",
      "\u001b[33mrecommended for nonsmooth problems.                                                          \u001b[0m ║ \n",
      "═════╦════════════╦════════════════╦═════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║  - │   -   ║  2.39541706590 ║   -  │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.109358   ║ \n",
      "   1 ║  - │   -   ║  2.39494727611 ║   -  │   -  ║ QN │    16 │ 2.119385 ║     1 │ 1.661377   ║ \n",
      "═════╩════════════╩════════════════╩═════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                         ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                ║ \n",
      "═════╦════════════╦════════════════╦═════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║    │       ║  2.39494727611 ║   -  │   -  ║    │       │          ║       │            ║ \n",
      "   B ║    │       ║  2.26591175934 ║   -  │   -  ║    │       │          ║       │            ║ \n",
      "═════╩════════════╩════════════════╩═════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              1                                                                    ║ \n",
      "Function evaluations:    58                                                                   ║ \n",
      "PyGRANSO termination code: 6 --- line search bracketed a minimizer but failed to satisfy      ║ \n",
      "Wolfe conditions.  This may be an indication that approximate stationarity has been attained. ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "# Main algorithm with logging enabled.\n",
    "soln = pygranso(var_spec= [var_in,model], combined_fn = comb_fn, user_opts = opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273777ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc = 0.075\n"
     ]
    }
   ],
   "source": [
    "# ## Train Accuracy\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "torch.nn.utils.vector_to_parameters(soln.final.x, model.parameters())\n",
    "outputs = model(inputs)\n",
    "acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "print(\"Train acc = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ffe16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# SETUP THE LOGGING FEATURES\n",
    "\n",
    "# Set up PyGRANSO's logging functions; pass opts.maxit to it so that\n",
    "# storage can be preallocated for efficiency.\n",
    "\n",
    "class HaltLog:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def haltLog(self, iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized,\n",
    "                ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level):\n",
    "\n",
    "        # DON'T CHANGE THIS\n",
    "        # increment the index/count\n",
    "        self.index += 1\n",
    "\n",
    "        # EXAMPLE:\n",
    "        # store history of x iterates in a preallocated cell array\n",
    "        self.x_iterates.append(x)\n",
    "        self.f.append(penaltyfn_parts.f)\n",
    "        self.tv.append(penaltyfn_parts.tv)\n",
    "\n",
    "        # self.f_grad.append(penaltyfn_parts.f_grad)\n",
    "        self.alpha.append(alpha)\n",
    "        self.stat_val.append(stat_val)\n",
    "\n",
    "        # keep this false unless you want to implement a custom termination\n",
    "        # condition\n",
    "        halt = False\n",
    "        return halt\n",
    "\n",
    "    # Once PyGRANSO has run, you may call this function to get retreive all\n",
    "    # the logging data stored in the shared variables, which is populated\n",
    "    # by haltLog being called on every iteration of PyGRANSO.\n",
    "    def getLog(self):\n",
    "        # EXAMPLE\n",
    "        # return x_iterates, trimmed to correct size\n",
    "        log = pygransoStruct()\n",
    "        log.x   = self.x_iterates[0:self.index]\n",
    "        log.f   = self.f[0:self.index]\n",
    "        log.tv  = self.tv[0:self.index]\n",
    "\n",
    "        # log.f_grad =  self.f_grad[0:self.index]\n",
    "        log.alpha = self.alpha[0:self.index]\n",
    "        log.stat_val = self.stat_val[0:self.index]\n",
    "        return log\n",
    "\n",
    "    def makeHaltLogFunctions(self,maxit):\n",
    "        # don't change these lambda functions\n",
    "        halt_log_fn = lambda iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized, ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level: self.haltLog(iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized, ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level)\n",
    "\n",
    "        get_log_fn = lambda : self.getLog()\n",
    "\n",
    "        # Make your shared variables here to store PyGRANSO history data\n",
    "        # EXAMPLE - store history of iterates x_0,x_1,...,x_k\n",
    "        self.index       = 0\n",
    "        self.x_iterates  = []\n",
    "        self.f           = []\n",
    "        self.tv          = []\n",
    "\n",
    "        # self.f_grad = []\n",
    "        self.alpha = []\n",
    "        self.stat_val = []\n",
    "\n",
    "\n",
    "        # Only modify the body of logIterate(), not its name or arguments.\n",
    "        # Store whatever data you wish from the current PyGRANSO iteration info,\n",
    "        # given by the input arguments, into shared variables of\n",
    "        # makeHaltLogFunctions, so that this data can be retrieved after PyGRANSO\n",
    "        # has been terminated.\n",
    "        #\n",
    "        # DESCRIPTION OF INPUT ARGUMENTS\n",
    "        #   iter                current iteration number\n",
    "        #   x                   current iterate x\n",
    "        #   penaltyfn_parts     struct containing the following\n",
    "        #       OBJECTIVE AND CONSTRAINTS VALUES\n",
    "        #       .f              objective value at x\n",
    "        #       .f_grad         objective gradient at x\n",
    "        #       .ci             inequality constraint at x\n",
    "        #       .ci_grad        inequality gradient at x\n",
    "        #       .ce             equality constraint at x\n",
    "        #       .ce_grad        equality gradient at x\n",
    "        #       TOTAL VIOLATION VALUES (inf norm, for determining feasibiliy)\n",
    "        #       .tvi            total violation of inequality constraints at x\n",
    "        #       .tve            total violation of equality constraints at x\n",
    "        #       .tv             total violation of all constraints at x\n",
    "        #       TOTAL VIOLATION VALUES (one norm, for L1 penalty function)\n",
    "        #       .tvi_l1         total violation of inequality constraints at x\n",
    "        #       .tvi_l1_grad    its gradient\n",
    "        #       .tve_l1         total violation of equality constraints at x\n",
    "        #       .tve_l1_grad    its gradient\n",
    "        #       .tv_l1          total violation of all constraints at x\n",
    "        #       .tv_l1_grad     its gradient\n",
    "        #       PENALTY FUNCTION VALUES\n",
    "        #       .p              penalty function value at x\n",
    "        #       .p_grad         penalty function gradient at x\n",
    "        #       .mu             current value of the penalty parameter\n",
    "        #       .feasible_to_tol logical indicating whether x is feasible\n",
    "        #   d                   search direction\n",
    "        #   get_BFGS_state_fn   function handle to get the (L)BFGS state data\n",
    "        #                       FULL MEMORY:\n",
    "        #                       - returns BFGS inverse Hessian approximation\n",
    "        #                       LIMITED MEMORY:\n",
    "        #                       - returns a struct with current L-BFGS state:\n",
    "        #                           .S          matrix of the BFGS s vectors\n",
    "        #                           .Y          matrix of the BFGS y vectors\n",
    "        #                           .rho        row vector of the 1/sty values\n",
    "        #                           .gamma      H0 scaling factor\n",
    "        #   H_regularized       regularized version of H\n",
    "        #                       [] if no regularization was applied to H\n",
    "        #   fn_evals            number of function evaluations incurred during\n",
    "        #                       this iteration\n",
    "        #   alpha               size of accepted size\n",
    "        #   n_gradients         number of previous gradients used for computing\n",
    "        #                       the termination QP\n",
    "        #   stat_vec            stationarity measure vector\n",
    "        #   stat_val            approximate value of stationarity:\n",
    "        #                           norm(stat_vec)\n",
    "        #                       gradients (result of termination QP)\n",
    "        #   fallback_level      number of strategy needed for a successful step\n",
    "        #                       to be taken.  See bfgssqpOptionsAdvanced.\n",
    "        #\n",
    "        # OUTPUT ARGUMENT\n",
    "        #   halt                set this to true if you wish optimization to\n",
    "        #                       be halted at the current iterate.  This can be\n",
    "        #                       used to create a custom termination condition,\n",
    "        return [halt_log_fn, get_log_fn]\n",
    "\n",
    "mHLF_obj = HaltLog()\n",
    "[halt_log_fn, get_log_fn] = mHLF_obj.makeHaltLogFunctions(opts.maxit)\n",
    "\n",
    "#  Set PyGRANSO's logging function in opts\n",
    "opts.halt_log_fn = halt_log_fn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GET THE HISTORY OF ITERATES\n",
    "# Even if an error is thrown, the log generated until the error can be\n",
    "# obtained by calling get_log_fn()\n",
    "log = get_log_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ded48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from makePlot import plot\n",
    "# plot(log,save_plot=True)\n",
    "# plot(log,save_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57a777a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log.stat_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63dee0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:52:21_Jan_09_2022\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "iters = range(0,len(log.f))\n",
    "\n",
    "\n",
    "path = '/home/buyun/Documents/GitHub/PyGRANSO/test/plots'\n",
    "os.chdir(path)\n",
    "ts = time.strftime('%H:%M:%S_%b_%d_%Y')\n",
    "print(ts)\n",
    "os.mkdir(ts)\n",
    "os.chdir(ts)\n",
    "\n",
    "fig, axs = plt.subplots(3)\n",
    "# fig.suptitle('Vertically stacked subplots')\n",
    "\n",
    "axs[0].plot(iters,log.f,'b-')\n",
    "axs[0].set_ylabel('obj val')\n",
    "# axs[0].xlabel('iter')\n",
    "\n",
    "axs[1].plot(iters,log.alpha,'k-')\n",
    "axs[1].set_ylabel('step_size')\n",
    "# axs[1].xlabel('iter')\n",
    "\n",
    "axs[2].plot(iters,log.stat_val,'r-')\n",
    "axs[2].set_ylabel('stationarity value')\n",
    "axs[2].set_xlabel('iter')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"output.png\", dpi=500)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
