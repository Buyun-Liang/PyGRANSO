{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5257bb27",
   "metadata": {},
   "source": [
    "<!-- # Dictionary Learning\n",
    "\n",
    "Solve orthogonal dictionary learning problem taken from: Bai, Yu, Qijia Jiang, and Ju Sun. \"Subgradient descent learns orthogonal dictionaries.\" arXiv preprint arXiv:1810.10702 (2018). -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b1ab10",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28993e76",
   "metadata": {},
   "source": [
    "<!-- Given data $\\{y_i \\}_{i \\in[m]}$ generated as $y_i = A x_i$, where $A \\in R^{n \\times n}$ is a fixed unknown orthogonal matrix and each $x_i \\in R^n$ is an iid Bernoulli-Gaussian random vector with parameter $\\theta \\in (0,1)$, recover $A$. \n",
    "\n",
    "Write $Y \\doteq [y_1,...,y_m]$ and $X \\doteq [x_1,...,x_m]$. To find the column of $A$, one can perform the following optimization:\n",
    "\n",
    "$$\\min_{q \\in R^n} f(q) \\doteq \\frac{1}{m} ||q^T Y||_{1} = \\frac{1}{m} \\sum_{i=1}^m |q^T y_i|,$$\n",
    "$$\\text{s.t.} ||q||_2 = 1$$\n",
    "\n",
    "This problem is nonconvex due to the constraint and nonsmooth due to the objective.\n",
    "\n",
    "Based on the above statistical model, $q^T Y = q^T A X$ has the highest sparsity when $q$ is a column of $A$ (up to sign) so that $q^T A$ is 1-sparse.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfdd50",
   "metadata": {},
   "source": [
    "## Modules Importing\n",
    "Import all necessary modules and add NCVX src folder to system path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ed32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy.linalg as la\n",
    "from scipy.stats import norm\n",
    "import sys\n",
    "## Adding NCVX directories. Should be modified by user\n",
    "sys.path.append('/home/buyun/Documents/GitHub/NCVX')\n",
    "from ncvx import ncvx\n",
    "from ncvxStruct import Options, GeneralStruct \n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from private.getNvar import getNvarTorch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a1b7fe",
   "metadata": {},
   "source": [
    "## Data Generation \n",
    "Specify torch device, model class, and generate data.\n",
    "\n",
    "NOTE: please specify path for downloading data.\n",
    "\n",
    "Use GPU for this problem. If no cuda device available, please set *device = torch.device('cpu')*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4842e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/buyun/anaconda3/envs/cuosqp_pygranso/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "batch_size = 100\n",
    "m = batch_size\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root = '/home/buyun/Documents/GitHub/NCVX/examples/data/mnist',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = False,            \n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root = '/home/buyun/Documents/GitHub/NCVX/examples/data/mnist', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "inputs, labels = next(iter(train_loader))\n",
    "inputs, labels = inputs.reshape(-1, 28 * 28).to(device=device, dtype=torch.double), labels.to(device=device)\n",
    "\n",
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim).to(device=device, dtype=torch.double)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x).to(device=device, dtype=torch.double)\n",
    "        return outputs\n",
    "    \n",
    "input_dim = 784\n",
    "output_dim = 10\n",
    "model = LogisticRegression(input_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9a7c1c",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "\n",
    "Specify optimization variables, and objective and constraint(s).\n",
    "\n",
    "Note: please strictly follow the format of comb_fn, which will be used in the NCVX main algortihm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2800db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables and corresponding dimensions.\n",
    "var_in = {}\n",
    "var_count = 0\n",
    "var_str = \"x\"\n",
    "for i in model.parameters():\n",
    "    # print(i.shape)\n",
    "    var_in[var_str+str(var_count)]= list(i.shape)\n",
    "    var_count += 1\n",
    "    \n",
    "lambda_r = 0.001\n",
    "\n",
    "def obj_eval_fn(X_struct):\n",
    "    # objective function\n",
    "    var_str = \"x\"\n",
    "    var_count = 0\n",
    "    for p in model.parameters():\n",
    "        tmpstr = var_str+str(var_count)\n",
    "        tmp_parameter = getattr(X_struct,tmpstr)\n",
    "        tmp_parameter.requires_grad_(True)\n",
    "        p.data = tmp_parameter # update model parameters\n",
    "        var_count += 1\n",
    "    \n",
    "    w = X_struct.x0\n",
    "    outputs = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    f = criterion(outputs, labels)  + lambda_r*torch.norm(w,p=1)\n",
    "    return f\n",
    "    \n",
    "\n",
    "def comb_fn(X_struct):\n",
    "    # objective function\n",
    "    var_str = \"x\"\n",
    "    var_count = 0\n",
    "    for p in model.parameters():\n",
    "        tmpstr = var_str+str(var_count)\n",
    "        tmp_parameter = getattr(X_struct,tmpstr)\n",
    "        tmp_parameter.requires_grad_(True)\n",
    "        p.data = tmp_parameter # update model parameters\n",
    "        var_count += 1\n",
    "        \n",
    "    w = X_struct.x0\n",
    "    outputs = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    f = criterion(outputs, labels) + lambda_r*torch.norm(w,p=1)\n",
    "    ci = None\n",
    "    ce = None\n",
    "    return [f,ci,ce]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc638c",
   "metadata": {},
   "source": [
    "## User Options\n",
    "Specify user-defined options for NCVX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "832f0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = Options()\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "opts.QPsolver = 'osqp' \n",
    "opts.maxit = 3000\n",
    "opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "opts.opt_tol = 1e-6\n",
    "opts.fvalquit = 1e-6\n",
    "opts.print_level = 1\n",
    "opts.print_frequency = 100\n",
    "# opts.print_ascii = True\n",
    "opts.halt_on_linesearch_bracket = False\n",
    "opts.max_fallback_level = 3\n",
    "opts.min_fallback_level = 2\n",
    "opts.init_step_size = 1e-2\n",
    "opts.linesearch_maxit = 25\n",
    "opts.is_backtrack_linesearch = True\n",
    "opts.searching_direction_rescaling = True\n",
    "opts.disable_terminationcode_6 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7700d",
   "metadata": {},
   "source": [
    "## Initial Test \n",
    "Check initial accuracy of the defined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e98147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial acc = 0.12\n"
     ]
    }
   ],
   "source": [
    "outputs = model(inputs )\n",
    "acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "\n",
    "print(\"Initial acc = {}\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a01da",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a52cfbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════╗\n",
      "\u001b[0m\u001b[33m║  NCVX requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001b[0m\u001b[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.              ║\n",
      "\u001b[0m\u001b[33m║  To disable this notice, set opts.quadprog_info_msg = False                               ║\n",
      "\u001b[0m\u001b[33m╚═══════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001b[0m══════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "NCVX: A User-Friendly and Scalable Package for Nonconvex Optimization in Machine Learning     ║ \n",
      "Version 1.1.1                                                                                 ║ \n",
      "MIT License Copyright (c) 2021 SUN Group @ UMN                                                ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                       ║ \n",
      " # of variables                     :   7850                                                  ║ \n",
      " # of inequality constraints        :      0                                                  ║ \n",
      " # of equality constraints          :      0                                                  ║ \n",
      "═════╦════════════╦════════════════╦═════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║  - │   -   ║  2.47011441957 ║   -  │   -  ║ -  │     1 │ 0.000000 ║     1 │ 1.488385   ║ \n",
      " 100 ║  - │   -   ║  1.53684772058 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     2 │ 0.010000 ║     1 │ 69234.27   ║ \n",
      " 200 ║  - │   -   ║  0.94315784520 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     2 │ 0.010000 ║     1 │ 86746.91   ║ \n",
      " 300 ║  - │   -   ║  0.64930544366 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     2 │ 0.010000 ║     1 │ 117681.2   ║ \n",
      " 400 ║  - │   -   ║  0.50821854569 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     2 │ 0.010000 ║     1 │ 142448.1   ║ \n",
      " 500 ║  - │   -   ║  0.45235119792 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     2 │ 0.010000 ║     1 │ 155003.8   ║ \n",
      " 600 ║  - │   -   ║  0.44801522985 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     6 │ 6.25e-04 ║     1 │ 161347.1   ║ \n",
      " 700 ║  - │   -   ║  0.44548164071 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     5 │ 0.001250 ║     1 │ 166751.6   ║ \n",
      " 800 ║  - │   -   ║  0.44329222030 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     6 │ 6.25e-04 ║     1 │ 171395.8   ║ \n",
      " 900 ║  - │   -   ║  0.44140818005 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     5 │ 0.001250 ║     1 │ 175444.7   ║ \n",
      "1000 ║  - │   -   ║  0.43986085819 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     6 │ 6.25e-04 ║     1 │ 179040.6   ║ \n",
      "1100 ║  - │   -   ║  0.43859377977 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     7 │ 3.13e-04 ║     1 │ 182303.3   ║ \n",
      "1200 ║  - │   -   ║  0.43753025127 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     6 │ 6.25e-04 ║     1 │ 185318.1   ║ \n",
      "1300 ║  - │   -   ║  0.43663430009 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     7 │ 3.13e-04 ║     1 │ 188147.6   ║ \n",
      "1400 ║  - │   -   ║  0.43588497706 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     7 │ 3.13e-04 ║     1 │ 190837.2   ║ \n",
      "1500 ║  - │   -   ║  0.43530010736 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     9 │ 7.81e-05 ║     2 │ 193412.9   ║ \n",
      "1600 ║  - │   -   ║  0.43477534931 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     8 │ 1.56e-04 ║     1 │ 195937.1   ║ \n",
      "1700 ║  - │   -   ║  0.43436877886 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     8 │ 1.56e-04 ║     1 │ 198391.2   ║ \n",
      "1800 ║  - │   -   ║  0.43400710165 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     9 │ 7.81e-05 ║     2 │ 200790.9   ║ \n",
      "1900 ║  - │   -   ║  0.43370603910 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │    11 │ 1.95e-05 ║     2 │ 203169.0   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ Penalty Fn ║                ║  Violation  ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║ Mu │ Value ║    Objective   ║ Ineq │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬════════════╬════════════════╬═════════════╬═══════════════════════╬════════════════════╣\n",
      "2000 ║  - │   -   ║  0.43345168936 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     9 │ 7.81e-05 ║     2 │ 205521.7   ║ \n",
      "2100 ║  - │   -   ║  0.43325944130 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │     9 │ 7.81e-05 ║     2 │ 207856.0   ║ \n",
      "2200 ║  - │   -   ║  0.43309787459 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │    10 │ 3.91e-05 ║     3 │ 210166.1   ║ \n",
      "2300 ║  - │   -   ║  0.43298610802 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │    10 │ 3.91e-05 ║     3 │ 212477.5   ║ \n",
      "2400 ║  - │   -   ║  0.43287113641 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │    11 │ 1.95e-05 ║     5 │ 214764.6   ║ \n",
      "2500 ║  - │   -   ║  0.43278195202 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │    14 │ 2.44e-06 ║     5 │ 217063.2   ║ \n",
      "2600 ║  - │   -   ║  0.43271544995 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │    11 │ 1.95e-05 ║     7 │ 219347.1   ║ \n",
      "2700 ║  - │   -   ║  0.43267049613 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │    13 │ 4.88e-06 ║    11 │ 221655.2   ║ \n",
      "2800 ║  - │   -   ║  0.43264406462 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │    14 │ 2.44e-06 ║    22 │ 223944.9   ║ \n",
      "2900 ║  - │   -   ║  0.43263958488 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │    26 │ 2.98e-10 ║    98 │ 226235.9   ║ \n",
      "3000 ║  - │   -   ║  0.43263958242 ║   -  │   -  ║ \u001b[33mGD\u001b[0m │    26 │ 2.98e-10 ║   100 │ 228534.9   ║ \n",
      "═════╩════════════╩════════════════╩═════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                         ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                ║ \n",
      "═════╦════════════╦════════════════╦═════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║    │       ║  0.43263958242 ║   -  │   -  ║    │       │          ║       │            ║ \n",
      "   B ║    │       ║  0.43263958242 ║   -  │   -  ║    │       │          ║       │            ║ \n",
      "═════╩════════════╩════════════════╩═════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              3000                                                                 ║ \n",
      "Function evaluations:    26252                                                                ║ \n",
      "NCVX termination code: 4 --- max iterations reached.                                          ║ \n",
      "══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "Total Wall Time: 42.66916370391846s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "soln = ncvx(combinedFunction = comb_fn, objEvalFunction = obj_eval_fn, var_dim_map = var_in, nn_model= model, torch_device = device, user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16b462",
   "metadata": {},
   "source": [
    "## Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db534484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc = 1.0\n"
     ]
    }
   ],
   "source": [
    "torch.nn.utils.vector_to_parameters(soln.final.x, model.parameters())\n",
    "outputs = model(inputs)\n",
    "acc = (outputs.max(1)[1] == labels).sum().item()/labels.size(0)\n",
    "print(\"Train acc = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df1c3c",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e190312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc = 0.74\n"
     ]
    }
   ],
   "source": [
    "test_inputs, test_labels = next(iter(test_loader))\n",
    "test_inputs, test_labels = test_inputs.reshape(-1, 28 * 28).to(device=device, dtype=torch.double), test_labels.to(device=device)\n",
    "    \n",
    "# test_labels = test_labels.to(device=device ) # label/target [256]\n",
    "# test_inputs = test_inputs.to(device=device, dtype=torch.double) # input data [256,3,32,32]\n",
    "\n",
    "test_outputs = model(test_inputs)\n",
    "test_acc = (test_outputs.max(1)[1] == test_labels).sum().item()/test_labels.size(0)\n",
    "print(\"Test acc = {}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
